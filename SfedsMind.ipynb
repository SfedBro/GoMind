{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "611eac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal AlphaZero-style skeleton for Go (self-play + MCTS + neural net)\n",
    "# Dependencies: torch, numpy\n",
    "\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "import copy\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f559e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1) Basic Go board\n",
    "# ---------------------------\n",
    "EMPTY = 0\n",
    "BLACK = 1\n",
    "WHITE = 2\n",
    "# Opponent's color\n",
    "def opponent(player: int) -> int:\n",
    "    return BLACK if player == WHITE else WHITE\n",
    "\n",
    "class Board:\n",
    "    def __init__(self, size:int=9, komi:float=0):\n",
    "        if komi == 0:\n",
    "            match (size): # New switch case notation\n",
    "                case (19):\n",
    "                    komi = 5.5\n",
    "                case (13):\n",
    "                    komi = 4.5 \n",
    "                case(9):\n",
    "                    komi = 3.5\n",
    "                case (_):\n",
    "                    komi = 1.5\n",
    "            # end match\n",
    "        self.size = size\n",
    "        self.komi = komi\n",
    "        self.grid = np.zeros((size, size), dtype=np.int8)\n",
    "        self.history = set()\n",
    "        self._add_history()\n",
    "        self.pass_count = 0\n",
    "\n",
    "    def copy(self):\n",
    "        b = Board(self.size, self.komi)\n",
    "        b.grid = self.grid.copy()\n",
    "        b.history = set(self.history)\n",
    "        b.pass_count = self.pass_count\n",
    "        return b\n",
    "\n",
    "    def in_bounds(self, x:int, y:int) -> bool:\n",
    "        return 0 <= x < self.size and 0 <= y < self.size\n",
    "\n",
    "    def neighbors(self, x:int, y:int):\n",
    "        for dx, dy in ((1,0),(-1,0),(0,1),(0,-1)):\n",
    "            nx, ny = x+dx, y+dy\n",
    "            if self.in_bounds(nx, ny):\n",
    "                yield nx, ny\n",
    "\n",
    "    def _board_tuple(self):\n",
    "        return tuple(self.grid.ravel().tolist())\n",
    "\n",
    "    def _add_history(self):\n",
    "        self.history.add(self._board_tuple())\n",
    "\n",
    "    def get(self, x:int, y:int) -> int:\n",
    "        return int(self.grid[y,x])\n",
    "\n",
    "    def set(self, x:int, y:int, v:int):\n",
    "        self.grid[y,x] = v\n",
    "\n",
    "    def _collect_group(self, x:int, y:int):\n",
    "        color = self.get(x, y)\n",
    "        if color == EMPTY:\n",
    "            return [], set()\n",
    "        visited = set()\n",
    "        stack = [(x,y)]\n",
    "        group = []\n",
    "        liberties = set()\n",
    "        while stack:\n",
    "            cx, cy = stack.pop()\n",
    "            if (cx, cy) in visited:\n",
    "                continue\n",
    "            visited.add((cx, cy))\n",
    "            group.append((cx, cy))\n",
    "            for nx, ny in self.neighbors(cx, cy):\n",
    "                val = self.get(nx, ny)\n",
    "                if val == color and (nx, ny) not in visited:\n",
    "                    stack.append((nx, ny))\n",
    "                elif val == EMPTY:\n",
    "                    liberties.add((nx, ny))\n",
    "        return group, liberties\n",
    "\n",
    "    def _remove_group(self, group: List[Tuple[int,int]]):\n",
    "        if not group:\n",
    "            return 0\n",
    "        col = self.get(group[0][0], group[0][1])\n",
    "        for x,y in group:\n",
    "            self.set(x,y,EMPTY)\n",
    "        return len(group)\n",
    "\n",
    "    def _adjacent_enemy_groups(self, x:int, y:int, player:int):\n",
    "        seen = set()\n",
    "        for nx, ny in self.neighbors(x,y):\n",
    "            if self.get(nx, ny) == opponent(player) and (nx, ny) not in seen:\n",
    "                seen.add((nx, ny))\n",
    "                yield nx, ny\n",
    "\n",
    "    def _play_move_no_checks(self, player:int, move:Optional[Tuple[int,int]]):\n",
    "        # move: None means pass\n",
    "        if move is None:\n",
    "            self.pass_count += 1\n",
    "            self._add_history()\n",
    "            return 0\n",
    "        x,y = move\n",
    "        self.set(x,y, player)\n",
    "        self.pass_count = 0\n",
    "        # capture adjacent enemy groups with zero liberties\n",
    "        removed = 0\n",
    "        to_remove = set()\n",
    "        for nx, ny in self.neighbors(x,y):\n",
    "            if self.get(nx, ny) == opponent(player):\n",
    "                g, libs = self._collect_group(nx, ny)\n",
    "                if len(libs) == 0:\n",
    "                    to_remove.update(g)\n",
    "        for rx, ry in to_remove:\n",
    "            self.set(rx, ry, EMPTY)\n",
    "            removed += 1\n",
    "        self._add_history()\n",
    "        return removed\n",
    "\n",
    "    def is_suicide(self, player:int, move:Tuple[int,int]) -> bool:\n",
    "        x,y = move\n",
    "        tmp = self.copy()\n",
    "        tmp.set(x,y, player)\n",
    "        # remove opponent dead groups\n",
    "        for nx, ny in tmp.neighbors(x,y):\n",
    "            if tmp.get(nx, ny) == opponent(player):\n",
    "                g, libs = tmp._collect_group(nx, ny)\n",
    "                if len(libs) == 0:\n",
    "                    tmp._remove_group(g)\n",
    "        # check own group's liberties\n",
    "        g, libs = tmp._collect_group(x,y)\n",
    "        return len(libs) == 0\n",
    "\n",
    "    def is_legal(self, player:int, move:Optional[Tuple[int,int]]) -> bool:\n",
    "        if move is None:\n",
    "            return True\n",
    "        x,y = move\n",
    "        if not self.in_bounds(x,y): return False\n",
    "        if self.get(x,y) != EMPTY: return False\n",
    "        # suicide\n",
    "        if self.is_suicide(player, (x,y)): return False\n",
    "        # superko (simple): simulate and check history\n",
    "        tmp = self.copy()\n",
    "        tmp._play_move_no_checks(player, (x,y))\n",
    "        if tmp._board_tuple() in self.history:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def legal_moves(self, player:int) -> List[Optional[Tuple[int,int]]]:\n",
    "        moves = []\n",
    "        for y in range(self.size):\n",
    "            for x in range(self.size):\n",
    "                if self.grid[y,x] == EMPTY and self.is_legal(player, (x,y)):\n",
    "                    moves.append((x,y))\n",
    "        moves.append(None)  # pass\n",
    "        return moves\n",
    "\n",
    "    def game_over(self) -> bool:\n",
    "        return self.pass_count >= 2\n",
    "\n",
    "    def score(self) -> Tuple[float,float]:\n",
    "        # area scoring (Chinese)\n",
    "        size = self.size\n",
    "        visited = np.zeros((size,size), dtype=bool)\n",
    "        black_area = 0\n",
    "        white_area = 0\n",
    "        for y in range(size):\n",
    "            for x in range(size):\n",
    "                v = self.get(x,y)\n",
    "                if v == BLACK: black_area += 1\n",
    "                elif v == WHITE: white_area += 1\n",
    "        from collections import deque\n",
    "        for y in range(size):\n",
    "            for x in range(size):\n",
    "                if self.get(x,y) != EMPTY or visited[y,x]:\n",
    "                    continue\n",
    "                q = deque()\n",
    "                q.append((x,y))\n",
    "                visited[y,x] = True\n",
    "                region = [(x,y)]\n",
    "                bordering = set()\n",
    "                while q:\n",
    "                    cx, cy = q.popleft()\n",
    "                    for nx, ny in self.neighbors(cx,cy):\n",
    "                        val = self.get(nx, ny)\n",
    "                        if val == EMPTY and not visited[ny,nx]:\n",
    "                            visited[ny,nx] = True\n",
    "                            q.append((nx,ny))\n",
    "                            region.append((nx,ny))\n",
    "                        elif val in (BLACK, WHITE):\n",
    "                            bordering.add(val)\n",
    "                if len(bordering) == 1:\n",
    "                    owner = next(iter(bordering))\n",
    "                    if owner == BLACK:\n",
    "                        black_area += len(region)\n",
    "                    else:\n",
    "                        white_area += len(region)\n",
    "        white_area += self.komi\n",
    "        return float(black_area), float(white_area)\n",
    "\n",
    "    def winner(self) -> int:\n",
    "        b, w = self.score()\n",
    "        return BLACK if b > w else WHITE\n",
    "\n",
    "    # helper: get neural network planes\n",
    "    def get_state_planes(self, player:int) -> np.ndarray:\n",
    "        # returns shape (3, size, size): black, white, to_move\n",
    "        black = (self.grid == BLACK).astype(np.float32)\n",
    "        white = (self.grid == WHITE).astype(np.float32)\n",
    "        turn_plane = np.full((self.size, self.size), 1.0 if player == BLACK else 0.0, dtype=np.float32)\n",
    "        return np.stack([black, white, turn_plane], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "450d4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 2) Neural network (PyTorch)\n",
    "# ---------------------------\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "    def forward(self, x):\n",
    "        return torch.relu(self.bn(self.conv(x)))\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = torch.relu(out + x)\n",
    "        return out\n",
    "\n",
    "class AlphaNet(nn.Module):\n",
    "    def __init__(self, board_size=9, num_res=3, channels=128):\n",
    "        super().__init__()\n",
    "        self.board_size = board_size\n",
    "        self.conv_in = ConvBlock(3, channels)\n",
    "        self.resblocks = nn.Sequential(*[ResidualBlock(channels) for _ in range(num_res)])\n",
    "        # policy head\n",
    "        self.p_conv = nn.Conv2d(channels, 2, 1)\n",
    "        self.p_bn = nn.BatchNorm2d(2)\n",
    "        self.p_fc = nn.Linear(2 * board_size * board_size, board_size * board_size + 1)  # +1 for pass\n",
    "        # value head\n",
    "        self.v_conv = nn.Conv2d(channels, 1, 1)\n",
    "        self.v_bn = nn.BatchNorm2d(1)\n",
    "        self.v_fc1 = nn.Linear(board_size * board_size, 64)\n",
    "        self.v_fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, 3, H, W]\n",
    "        out = self.conv_in(x)\n",
    "        out = self.resblocks(out)\n",
    "        # policy\n",
    "        p = torch.relu(self.p_bn(self.p_conv(out)))\n",
    "        p = p.view(p.size(0), -1)\n",
    "        logits = self.p_fc(p)  # shape [B, H*W + 1]\n",
    "        logp = torch.log_softmax(logits, dim=1)\n",
    "        # value\n",
    "        v = torch.relu(self.v_bn(self.v_conv(out)))\n",
    "        v = v.view(v.size(0), -1)\n",
    "        v = torch.relu(self.v_fc1(v))\n",
    "        value = torch.tanh(self.v_fc2(v)).squeeze(1)\n",
    "        return logp, value  # log probabilities and scalar value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "346a66cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 3) MCTS with PUCT\n",
    "# ---------------------------\n",
    "class MCTSNode:\n",
    "    def __init__(self, prior:float=0.0):\n",
    "        self.prior = prior  # P(a)\n",
    "        self.visit_count = 0  # N\n",
    "        self.value_sum = 0.0  # W\n",
    "        self.children = {}  # action -> MCTSNode\n",
    "\n",
    "    def q_value(self):\n",
    "        if self.visit_count == 0:\n",
    "            return 0.0\n",
    "        return self.value_sum / self.visit_count\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, net:AlphaNet, board_size:int, c_puct:float=1.0, n_simulations:int=80, device='cpu'):\n",
    "        self.net = net\n",
    "        self.board_size = board_size\n",
    "        self.c_puct = c_puct\n",
    "        self.n_simulations = n_simulations\n",
    "        self.device = device\n",
    "\n",
    "    def run(self, root_board:Board, to_move:int):\n",
    "        root = MCTSNode()\n",
    "        # evaluate root with network to get priors\n",
    "        state = torch.tensor(root_board.get_state_planes(to_move), dtype=torch.float32).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            logp, v = self.net(state.to(self.device))\n",
    "        probs = torch.exp(logp).squeeze(0).cpu().numpy()  # length = H*W + 1\n",
    "        legal = root_board.legal_moves(to_move)\n",
    "        # map actions to indices: index = y * size + x, pass = size*size\n",
    "        size = self.board_size\n",
    "        legal_indices = []\n",
    "        for mv in legal:\n",
    "            if mv is None:\n",
    "                idx = size*size\n",
    "            else:\n",
    "                idx = mv[1]*size + mv[0]\n",
    "            legal_indices.append(idx)\n",
    "        # initialize children with prior P from network but zero prior for illegal\n",
    "        for idx in legal_indices:\n",
    "            root.children[idx] = MCTSNode(prior=float(probs[idx]))\n",
    "        # run simulations\n",
    "        for _ in range(self.n_simulations):\n",
    "            board_copy = root_board.copy()\n",
    "            self._simulate(board_copy, to_move, root)\n",
    "        # build policy target pi from visit counts\n",
    "        counts = np.zeros(self.board_size*self.board_size + 1, dtype=np.float32)\n",
    "        for a, node in root.children.items():\n",
    "            counts[a] = node.visit_count\n",
    "        pi = counts / counts.sum() if counts.sum() > 0 else counts\n",
    "        return pi  # return visit-probabilities\n",
    "\n",
    "    def _select_child(self, node:MCTSNode, total_N:float):\n",
    "        # choose action maximizing Q + U\n",
    "        best_score = -1e9\n",
    "        best_action = None\n",
    "        best_child = None\n",
    "        for a, child in node.children.items():\n",
    "            Q = child.q_value()\n",
    "            U = self.c_puct * child.prior * math.sqrt(total_N) / (1 + child.visit_count)\n",
    "            score = Q + U\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_action = a\n",
    "                best_child = child\n",
    "        return best_action, best_child\n",
    "\n",
    "    def _simulate(self, board:Board, to_move:int, root:MCTSNode):\n",
    "        path = []\n",
    "        node = root\n",
    "        player = to_move\n",
    "        # selection & expansion\n",
    "        while True:\n",
    "            if len(node.children) == 0:\n",
    "                # leaf\n",
    "                break\n",
    "            total_N = sum(child.visit_count for child in node.children.values())\n",
    "            action_idx, child = self._select_child(node, total_N)\n",
    "            # apply action\n",
    "            if action_idx == self.board_size*self.board_size:\n",
    "                mv = None\n",
    "            else:\n",
    "                x = action_idx % self.board_size\n",
    "                y = action_idx // self.board_size\n",
    "                mv = (x,y)\n",
    "            board._play_move_no_checks(player, mv)\n",
    "            path.append((node, action_idx, player))\n",
    "            # if the chosen child has no children yet, expand it using network\n",
    "            node = child\n",
    "            player = opponent(player)\n",
    "            if len(node.children) == 0:\n",
    "                break\n",
    "        # Evaluate leaf with neural net\n",
    "        state = torch.tensor(board.get_state_planes(player), dtype=torch.float32).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            logp, v = self.net(state.to(self.device))\n",
    "        probs = torch.exp(logp).squeeze(0).cpu().numpy()\n",
    "        # expand node with legal moves\n",
    "        legal = board.legal_moves(player)\n",
    "        for mv in legal:\n",
    "            if mv is None:\n",
    "                idx = self.board_size*self.board_size\n",
    "            else:\n",
    "                idx = mv[1]*self.board_size + mv[0]\n",
    "            if idx not in node.children:\n",
    "                node.children[idx] = MCTSNode(prior=float(probs[idx]))\n",
    "        value = float(v.item())\n",
    "        # backup value up the path\n",
    "        for parent, action_idx, player_at_parent in reversed(path):\n",
    "            # note: v is from viewpoint of 'player' who was to move at leaf; when backpropagating,\n",
    "            # we need the value from parent perspective: if parent.player != player, flip sign.\n",
    "            parent.visit_count += 1\n",
    "            parent.value_sum += value\n",
    "            value = -value  # alternate perspective\n",
    "        # if path empty (root leaf), still need to update root? handled in outer loop via children counts\n",
    "        # When we expanded root.children initially, root had children; after first selection we update nodes above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a028b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 4) Replay buffer and self-play\n",
    "# ---------------------------\n",
    "Example = collections.namedtuple('Example', ['state', 'pi', 'z'])\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity=10000):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, example:Example):\n",
    "        self.buffer.append(example)\n",
    "\n",
    "    def sample(self, batch_size:int):\n",
    "        batch = random.sample(self.buffer, min(batch_size, len(self.buffer)))\n",
    "        states = np.stack([e.state for e in batch], axis=0)  # [B, 3, H, W]\n",
    "        pis = np.stack([e.pi for e in batch], axis=0)       # [B, A]\n",
    "        zs = np.array([e.z for e in batch], dtype=np.float32)  # [B]\n",
    "        return states, pis, zs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "def self_play_episode(net:AlphaNet, mcts:MCTS, board_size:int, n_simulations:int, temperature:float=1.0):\n",
    "    board = Board(size=board_size)\n",
    "    to_move = BLACK\n",
    "    examples:List[Example] = []\n",
    "    move_no = 0\n",
    "    while not board.game_over() and move_no < board_size*board_size*4:\n",
    "        pi = mcts.run(board, to_move)  # uses net internally\n",
    "        # apply temperature: simple softmax on visit counts (here pi already normalized)\n",
    "        if temperature == 0:\n",
    "            # pick argmax\n",
    "            a = int(np.argmax(pi))\n",
    "        else:\n",
    "            p = pi ** (1.0 / temperature)\n",
    "            p = p / (p.sum() + 1e-12)\n",
    "            a = int(np.random.choice(len(p), p=p))\n",
    "        # store example: state plane for current player, policy pi (from MCTS), z unknown yet\n",
    "        state = board.get_state_planes(to_move)\n",
    "        examples.append(Example(state=state, pi=pi.copy(), z=None))\n",
    "        # convert a to move\n",
    "        if a == board_size*board_size:\n",
    "            mv = None\n",
    "        else:\n",
    "            mv = (a % board_size, a // board_size)\n",
    "        board._play_move_no_checks(to_move, mv)\n",
    "        to_move = opponent(to_move)\n",
    "        move_no += 1\n",
    "    # game finished: compute z for each example (from perspective of player to move at that state)\n",
    "    winner = board.winner()\n",
    "    for ex in examples:\n",
    "        # if winner == BLACK -> z=+1 for states where to_move was BLACK, else -1\n",
    "        # but ex.state includes turn_plane indicating player at that state: turn_plane=1.0 means black to move\n",
    "        turn_plane = ex.state[2]\n",
    "        black_to_move = bool(turn_plane[0,0] > 0.5)\n",
    "        if winner == BLACK:\n",
    "            z = 1.0 if black_to_move else -1.0\n",
    "        else:\n",
    "            z = 1.0 if not black_to_move else -1.0  # if white won, z=+1 for white-to-move states\n",
    "        # replace example with z\n",
    "        ex_z = Example(state=ex.state, pi=ex.pi, z=z)\n",
    "        yield ex_z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5fd421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 5) Training loop (simple)\n",
    "# ---------------------------\n",
    "def train_loop(board_size=9,\n",
    "               n_iterations=100,\n",
    "               self_play_games_per_iter=10,\n",
    "               mcts_simulations=50,\n",
    "               batch_size=64,\n",
    "               epochs=1,\n",
    "               device='cpu'):\n",
    "    device = torch.device(device)\n",
    "    net = AlphaNet(board_size=board_size, num_res=3, channels=64).to(device)\n",
    "    mcts = MCTS(net, board_size=board_size, c_puct=1.0, n_simulations=mcts_simulations, device=device)\n",
    "    buffer = ReplayBuffer(capacity=20000)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "    for it in range(n_iterations):\n",
    "        # 1) self-play to fill buffer\n",
    "        for g in range(self_play_games_per_iter):\n",
    "            for ex in self_play_episode(net, mcts, board_size, mcts_simulations, temperature=1.0):\n",
    "                buffer.push(ex)\n",
    "        print(f\"Iter {it}: buffer size = {len(buffer)}\")\n",
    "        # 2) train network on buffer\n",
    "        for epoch in range(epochs):\n",
    "            if len(buffer) < batch_size:\n",
    "                continue\n",
    "            states, pis, zs = buffer.sample(batch_size)\n",
    "            states_t = torch.tensor(states, dtype=torch.float32).to(device)\n",
    "            pis_t = torch.tensor(pis, dtype=torch.float32).to(device)\n",
    "            zs_t = torch.tensor(zs, dtype=torch.float32).to(device)\n",
    "            logp, v = net(states_t)\n",
    "            # policy loss: cross entropy between pi (target visit dist) and predicted logp\n",
    "            policy_loss = - (pis_t * logp).sum(dim=1).mean()\n",
    "            value_loss = ((v - zs_t) ** 2).mean()\n",
    "            loss = policy_loss + value_loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Iter {it}: training done\")\n",
    "\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0727c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: buffer size = 194\n",
      "Iter 0: training done\n",
      "Iter 1: buffer size = 350\n",
      "Iter 1: training done\n",
      "Iter 2: buffer size = 458\n",
      "Iter 2: training done\n",
      "Iter 3: buffer size = 560\n",
      "Iter 3: training done\n",
      "Iter 4: buffer size = 600\n",
      "Iter 4: training done\n",
      "Iter 5: buffer size = 689\n",
      "Iter 5: training done\n",
      "Iter 6: buffer size = 723\n",
      "Iter 6: training done\n",
      "Iter 7: buffer size = 822\n",
      "Iter 7: training done\n",
      "Iter 8: buffer size = 864\n",
      "Iter 8: training done\n",
      "Iter 9: buffer size = 899\n",
      "Iter 9: training done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 6) Quick run\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # quick demo: small run, not intended to reach strong play\n",
    "    net = train_loop(board_size=9,\n",
    "                     n_iterations=10,\n",
    "                     self_play_games_per_iter=2,\n",
    "                     mcts_simulations=32,\n",
    "                     batch_size=32,\n",
    "                     epochs=1,\n",
    "                     device='cpu')\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aca5963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game finished. Close window to exit.\n"
     ]
    }
   ],
   "source": [
    "# watch_match.py  (или вставь в конец az_go.py)\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# опционально: pygame рендер\n",
    "try:\n",
    "    import pygame\n",
    "    PYGAME_OK = True\n",
    "except Exception:\n",
    "    PYGAME_OK = False\n",
    "\n",
    "def load_net(path: str, board_size: int, device='cpu'):\n",
    "    \"\"\"Создает AlphaNet и загружает веса из path (torch .pth/.pt).\"\"\"\n",
    "    net = AlphaNet(board_size=board_size, num_res=3, channels=64)\n",
    "    net.load_state_dict(torch.load(path, map_location=device))\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    return net\n",
    "\n",
    "def board_to_ascii(board: Board):\n",
    "    \"\"\"Возвращает строковое представление доски ('.' empty, 'X' black, 'O' white).\"\"\"\n",
    "    lines = []\n",
    "    for y in range(board.size):\n",
    "        row = []\n",
    "        for x in range(board.size):\n",
    "            v = board.get(x, y)\n",
    "            if v == EMPTY:\n",
    "                row.append('.')\n",
    "            elif v == BLACK:\n",
    "                row.append('X')\n",
    "            else:\n",
    "                row.append('O')\n",
    "        lines.append(''.join(row))\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "class PygameRenderer:\n",
    "    def __init__(self, board_size=9, cell_size=30, padding=20):\n",
    "        if not PYGAME_OK:\n",
    "            raise RuntimeError(\"pygame not available\")\n",
    "        self.board_size = board_size\n",
    "        self.cell_size = cell_size\n",
    "        self.padding = padding\n",
    "        self.width = board_size * cell_size + padding * 2\n",
    "        self.height = self.width\n",
    "        self.last_pass = False\n",
    "        pygame.init()\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        pygame.display.set_caption(\"Watch Match\")\n",
    "        self.font = pygame.font.SysFont(None, 24)\n",
    "\n",
    "    def draw(self, board: Board, to_move):\n",
    "        self.screen.fill((210, 170, 110))\n",
    "        PADDING = self.padding\n",
    "        CELL = self.cell_size\n",
    "        STONE_R = int(CELL * 0.4)\n",
    "        # grid\n",
    "        for i in range(self.board_size):\n",
    "            pygame.draw.line(\n",
    "                self.screen, (0,0,0),\n",
    "                (PADDING, PADDING + i*CELL),\n",
    "                (PADDING + (self.board_size-1)*CELL, PADDING + i*CELL), 1)\n",
    "            pygame.draw.line(\n",
    "                self.screen, (0,0,0),\n",
    "                (PADDING + i*CELL, PADDING),\n",
    "                (PADDING + i*CELL, PADDING + (self.board_size-1)*CELL), 1)\n",
    "        # hoshi\n",
    "        hoshi = [3, 9, 15]\n",
    "        for hx in hoshi:\n",
    "            for hy in hoshi:\n",
    "                if 0 <= hx < self.board_size and 0 <= hy < self.board_size:\n",
    "                    pygame.draw.circle(self.screen, (0,0,0),\n",
    "                        (PADDING + hx*CELL, PADDING + hy*CELL), max(2, int(CELL*0.08)))\n",
    "        # stones\n",
    "        for y in range(self.board_size):\n",
    "            for x in range(self.board_size):\n",
    "                v = board.get(x,y)\n",
    "                if v == BLACK:\n",
    "                    pygame.draw.circle(self.screen, (0,0,0),\n",
    "                        (PADDING + x*CELL, PADDING + y*CELL), STONE_R)\n",
    "                elif v == WHITE:\n",
    "                    pygame.draw.circle(self.screen, (255,255,255),\n",
    "                        (PADDING + x*CELL, PADDING + y*CELL), STONE_R)\n",
    "        # turn text\n",
    "        txt = \"Black to move\" if to_move == BLACK else \"White to move\"\n",
    "        if self.last_pass: txt = \"White passed\" if to_move == BLACK else \"Black passed\"\n",
    "        surf = self.font.render(txt, True, (0,0,0))\n",
    "        self.screen.blit(surf, (5,5))\n",
    "        pygame.display.flip()\n",
    "\n",
    "def pick_action_from_pi(pi: np.ndarray, board: Board, board_size:int, temperature:float=0.0):\n",
    "    \"\"\"pi is visit-probabilities (length board_size*board_size+1). Returns chosen action index.\"\"\"\n",
    "    # mask illegal moves\n",
    "    current_player = None\n",
    "    legal = board.legal_moves(current_player)  # we will set current_player outside, but easier pass as global? avoid\n",
    "    # Better: build legal mask here by checking each index\n",
    "    mask = np.zeros_like(pi, dtype=np.bool_)\n",
    "    for mv in board.legal_moves(current_player):\n",
    "        if mv is None:\n",
    "            idx = board_size*board_size\n",
    "        else:\n",
    "            idx = mv[1]*board_size + mv[0]\n",
    "        mask[idx] = True\n",
    "    masked = np.copy(pi)\n",
    "    masked[~mask] = 0.0\n",
    "    s = masked.sum()\n",
    "    if s <= 0:\n",
    "        # fallback: uniform over legal\n",
    "        legal_idxs = np.where(mask)[0]\n",
    "        return int(np.random.choice(legal_idxs))\n",
    "    masked = masked / s\n",
    "    if temperature == 0.0:\n",
    "        return int(np.argmax(masked))\n",
    "    else:\n",
    "        p = masked ** (1.0 / temperature)\n",
    "        p = p / p.sum()\n",
    "        return int(np.random.choice(len(p), p=p))\n",
    "\n",
    "def play_match(net1: AlphaNet,\n",
    "               net2: AlphaNet,\n",
    "               board_size:int=9,\n",
    "               mcts_simulations:int=160,\n",
    "               c_puct:float=1.0,\n",
    "               device='cpu',\n",
    "               render: str = 'console',  # 'console' or 'pygame'\n",
    "               pause_time: float = 0.5,\n",
    "               temperature: float = 0.0):\n",
    "    \"\"\"\n",
    "    Провести партию между net1 (играет Black) и net2 (White).\n",
    "    render = 'console' или 'pygame'. pause_time в секундах между ходами.\n",
    "    \"\"\"\n",
    "    # подготовка MCTS для каждой сети\n",
    "    mcts1 = MCTS(net1, board_size=board_size, c_puct=c_puct, n_simulations=mcts_simulations, device=device)\n",
    "    mcts2 = MCTS(net2, board_size=board_size, c_puct=c_puct, n_simulations=mcts_simulations, device=device)\n",
    "\n",
    "    board = Board(size=board_size)\n",
    "    to_move = BLACK\n",
    "    move_no = 0\n",
    "\n",
    "    renderer = None\n",
    "    if render == 'pygame':\n",
    "        if not PYGAME_OK:\n",
    "            print(\"pygame not available, falling back to console render\")\n",
    "            render = 'console'\n",
    "        else:\n",
    "            renderer = PygameRenderer(board_size=board_size, cell_size=30, padding=20)\n",
    "\n",
    "    # main loop\n",
    "    while not board.game_over() and move_no < board_size*board_size*4:\n",
    "        if render == 'console':\n",
    "            print(\"\\nMove\", move_no, \"to_move:\", \"BLACK\" if to_move==BLACK else \"WHITE\")\n",
    "            print(board_to_ascii(board))\n",
    "        elif render == 'pygame':\n",
    "            renderer.draw(board, to_move)\n",
    "            # handle events to allow window close\n",
    "            for ev in pygame.event.get():\n",
    "                if ev.type == pygame.QUIT:\n",
    "                    pygame.quit()\n",
    "                    return\n",
    "\n",
    "        # choose MCTS for current player\n",
    "        if to_move == BLACK:\n",
    "            pi = mcts1.run(board, to_move)  # visit-probs\n",
    "        else:\n",
    "            pi = mcts2.run(board, to_move)\n",
    "\n",
    "        # pick action deterministically if temperature==0\n",
    "        # convert pi to mask and argmax\n",
    "        # build legal mask and choose\n",
    "        size = board_size\n",
    "        mask = np.zeros_like(pi, dtype=np.bool_)\n",
    "        for mv in board.legal_moves(to_move):\n",
    "            if mv is None:\n",
    "                idx = size*size\n",
    "            else:\n",
    "                idx = mv[1]*size + mv[0]\n",
    "            mask[idx] = True\n",
    "        masked = np.copy(pi)\n",
    "        masked[~mask] = 0.0\n",
    "        if masked.sum() <= 0:\n",
    "            # fallback random legal\n",
    "            legal = board.legal_moves(to_move)\n",
    "            mv = random.choice(legal)\n",
    "        else:\n",
    "            if temperature == 0.0:\n",
    "                a = int(np.argmax(masked))\n",
    "            else:\n",
    "                p = masked ** (1.0 / temperature)\n",
    "                p = p / p.sum()\n",
    "                a = int(np.random.choice(len(p), p=p))\n",
    "            if a == size*size:\n",
    "                mv = None\n",
    "            else:\n",
    "                mv = (a % size, a // size)\n",
    "            renderer.last_pass = mv == None\n",
    "\n",
    "        # apply move (we use internal _play_move_no_checks to avoid extra superko checks done by is_legal,\n",
    "        # but to be safe, you can check is_legal before applying)\n",
    "        if mv is None:\n",
    "            board._play_move_no_checks(to_move, None)\n",
    "        else:\n",
    "            # ensure legal\n",
    "            if board.is_legal(to_move, mv):\n",
    "                board._play_move_no_checks(to_move, mv)\n",
    "            else:\n",
    "                # illegal (shouldn't happen if mask built correctly), pick random legal\n",
    "                legal = board.legal_moves(to_move)\n",
    "                mv = random.choice(legal)\n",
    "                board._play_move_no_checks(to_move, mv)\n",
    "\n",
    "        to_move = opponent(to_move)\n",
    "        move_no += 1\n",
    "        time.sleep(pause_time)\n",
    "\n",
    "    # finished\n",
    "    bscore, wscore = board.score()\n",
    "    winner = board.winner()\n",
    "    if render == 'console':\n",
    "        print(\"\\nFinal board:\")\n",
    "        print(board_to_ascii(board))\n",
    "        print(f\"Score Black: {bscore:.1f}, White(with komi): {wscore:.1f}\")\n",
    "        print(\"Winner:\", \"BLACK\" if winner==BLACK else \"WHITE\")\n",
    "    elif render == 'pygame':\n",
    "        renderer.draw(board, to_move)\n",
    "        print(\"Game finished. Close window to exit.\")\n",
    "        # keep window open until closed\n",
    "        while True:\n",
    "            for ev in pygame.event.get():\n",
    "                if ev.type == pygame.QUIT:\n",
    "                    pygame.quit()\n",
    "                    return\n",
    "            time.sleep(0.1)\n",
    "\n",
    "# ---------------------------\n",
    "# Example usage:\n",
    "# ---------------------------\n",
    "# 1) если у тебя есть сохраненные веса:\n",
    "# net_black = load_net(\"best_black.pth\", board_size=9, device='cpu')\n",
    "# net_white = load_net(\"best_white.pth\", board_size=9, device='cpu')\n",
    "# play_match(net_black, net_white, board_size=9, mcts_simulations=128, render='console')\n",
    "\n",
    "# 2) если у тебя есть одна сеть (самонаблюдение), можно использовать одну и ту же модель:\n",
    "# net = load_net(\"model.pth\", board_size=9)\n",
    "# play_match(net, net, board_size=9, mcts_simulations=128, render='pygame', pause_time=0.4)\n",
    "\n",
    "# 3) если ты вызвал train_loop и получил net object:\n",
    "# net_trained = train_loop(...)\n",
    "# play_match(net_trained, net_trained, board_size=9, mcts_simulations=128, render='console')\n",
    "play_match(net, net, board_size=9, mcts_simulations=128, render='pygame', pause_time=0.4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
